{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SignSpeak Inference Server - Google Colab Deployment\n",
                "\n",
                "Deploy the SignSpeak ML backend on Google Colab with **T4 GPU** for zero-cost inference.\n",
                "\n",
                "## ‚ö° Quick Start\n",
                "1. **Runtime** ‚Üí **Change runtime type** ‚Üí Select **T4 GPU**\n",
                "2. Run all cells in order (Ctrl+F9 or Runtime ‚Üí Run all)\n",
                "3. Copy the tunnel URL from Cell 4 output\n",
                "4. Update `COLAB_TUNNEL_URL` in Cloudflare Pages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: Install Dependencies\n",
                "print(\"üì¶ Installing dependencies...\")\n",
                "\n",
                "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
                "!pip install -q fastapi uvicorn[standard] pydantic python-multipart\n",
                "!pip install -q pycloudflared\n",
                "\n",
                "print(\"‚úÖ Dependencies installed successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: Clone Repository\n",
                "import os\n",
                "\n",
                "print(\"üì• Cloning SignSpeak repository...\")\n",
                "\n",
                "# Remove existing directory if present\n",
                "if os.path.exists('SignSpeak-Final-Year-Project'):\n",
                "    !rm -rf SignSpeak-Final-Year-Project\n",
                "\n",
                "!git clone https://github.com/KathiravanKOffl/SignSpeak-Final-Year-Project.git\n",
                "%cd SignSpeak-Final-Year-Project/backend\n",
                "\n",
                "print(f\"‚úÖ Repository cloned!\")\n",
                "print(f\"üìÇ Current directory: {os.getcwd()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: Verify GPU\n",
                "import torch\n",
                "\n",
                "print(\"üîç Checking GPU availability...\\n\")\n",
                "print(f\"üñ•Ô∏è  Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
                "print(f\"üíæ CUDA Available: {torch.cuda.is_available()}\")\n",
                "print(f\"üî• PyTorch Version: {torch.__version__}\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"‚úÖ GPU ready for inference!\")\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è  GPU not available - using CPU (slower)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: Start Cloudflare Tunnel\n",
                "from pycloudflared import try_cloudflare\n",
                "import threading\n",
                "import time\n",
                "\n",
                "print(\"üåê Starting Cloudflare Tunnel...\\n\")\n",
                "\n",
                "tunnel_url = None\n",
                "\n",
                "def start_tunnel():\n",
                "    global tunnel_url\n",
                "    try:\n",
                "        url_obj = try_cloudflare(port=8000, verbose=True)\n",
                "        tunnel_url = url_obj.tunnel\n",
                "        print(f\"\\n\" + \"=\"*70)\n",
                "        print(f\"‚úÖ TUNNEL ACTIVE!\")\n",
                "        print(f\"\\nüìã COPY THIS URL:\")\n",
                "        print(f\"    {tunnel_url}\")\n",
                "        print(f\"\\n\" + \"=\"*70)\n",
                "        print(f\"\\nüîß Next Steps:\")\n",
                "        print(f\"   1. Copy the URL above\")\n",
                "        print(f\"   2. Go to Cloudflare Pages dashboard\")\n",
                "        print(f\"   3. Settings ‚Üí Environment variables\")\n",
                "        print(f\"   4. Update COLAB_TUNNEL_URL with this URL\")\n",
                "        print(f\"   5. Redeploy your Pages project\")\n",
                "        print(f\"\\n\" + \"=\"*70)\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Tunnel error: {e}\")\n",
                "\n",
                "# Start tunnel in background\n",
                "tunnel_thread = threading.Thread(target=start_tunnel, daemon=True)\n",
                "tunnel_thread.start()\n",
                "\n",
                "# Wait for tunnel to initialize\n",
                "print(\"‚è≥ Waiting for tunnel to start...\")\n",
                "time.sleep(10)\n",
                "\n",
                "if tunnel_url:\n",
                "    print(f\"\\n‚úÖ Tunnel is ready!\")\n",
                "    print(f\"üåê URL: {tunnel_url}\")\n",
                "else:\n",
                "    print(f\"\\n‚è≥ Tunnel is starting... Check output above for URL\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: Start FastAPI Server\n",
                "print(\"üöÄ Starting FastAPI inference server...\")\n",
                "print(\"‚ö†Ô∏è  This cell will run indefinitely - that's normal!\")\n",
                "print(\"üìù Server logs will appear below\")\n",
                "print(\"üõë Press the stop button to shut down the server\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "!python -m uvicorn api.inference_server:app --host 0.0.0.0 --port 8000 --reload"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: Keep-Alive Monitor (Optional)\n",
                "# Run this in a separate cell if Colab tends to disconnect\n",
                "\n",
                "import time\n",
                "from IPython.display import clear_output\n",
                "\n",
                "print(\"‚è∞ Keep-alive monitor active...\")\n",
                "counter = 0\n",
                "\n",
                "try:\n",
                "    while True:\n",
                "        counter += 1\n",
                "        clear_output(wait=True)\n",
                "        print(f\"‚è∞ Server uptime: {counter} minutes\")\n",
                "        print(f\"üåê Tunnel URL: {tunnel_url if tunnel_url else 'Check Cell 4 output'}\")\n",
                "        print(f\"üíö Colab session: ACTIVE\")\n",
                "        print(f\"üñ•Ô∏è  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
                "        print(f\"\\nüí° Tip: Keep this tab open to prevent session timeout\")\n",
                "        print(f\"‚è±Ô∏è  Colab free tier: 12 hours max per session\")\n",
                "        time.sleep(60)\n",
                "except KeyboardInterrupt:\n",
                "    print(\"\\nüõë Keep-alive stopped.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß™ Testing\n",
                "\n",
                "After starting the server, test these endpoints:\n",
                "\n",
                "### Health Check\n",
                "```bash\n",
                "curl https://your-tunnel-url.trycloudflare.com/health\n",
                "```\n",
                "\n",
                "### Prediction\n",
                "```bash\n",
                "curl -X POST https://your-tunnel-url.trycloudflare.com/predict \\\n",
                "  -H \"Content-Type: application/json\" \\\n",
                "  -d '{\"landmarks\": {...}}'\n",
                "```\n",
                "\n",
                "## üìä Resource Usage\n",
                "\n",
                "- **GPU**: T4 (16GB VRAM)\n",
                "- **RAM**: ~12GB available\n",
                "- **Disk**: ~100GB available\n",
                "- **Session**: 12 hours max (free tier)\n",
                "\n",
                "## üîÑ Session Management\n",
                "\n",
                "If session expires or disconnects:\n",
                "1. Runtime ‚Üí Restart runtime\n",
                "2. Run all cells again (Ctrl+F9)\n",
                "3. Copy new tunnel URL\n",
                "4. Update Cloudflare environment variable\n",
                "\n",
                "## üéØ Production Tips\n",
                "\n",
                "For 24/7 availability, consider:\n",
                "- Google Colab Pro ($10/month) - longer sessions\n",
                "- Paperspace Gradient (free tier available)\n",
                "- Lightning AI (free tier available)\n",
                "- Or deploy to Cloud Run / AWS Lambda\n"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}