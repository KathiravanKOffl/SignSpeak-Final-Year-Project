{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Create file_to_label.json for ISL-123 Cache\n",
                "\n",
                "**Problem:** Cache exists but file_to_label.json is missing  \n",
                "**Solution:** Scan INCLUDE dataset and map each cache file to its class  \n",
                "**Runtime:** ~30 seconds\n",
                "\n",
                "---\n",
                "\n",
                "### What this does:\n",
                "1. Scans INCLUDE dataset folder structure\n",
                "2. Matches cache filenames to source videos\n",
                "3. Creates file_to_label.json mapping\n",
                "4. Verifies all 123 classes are represented"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 1: Setup\n",
                "# ============================================================\n",
                "import json\n",
                "import os\n",
                "from pathlib import Path\n",
                "from collections import Counter, defaultdict\n",
                "from tqdm import tqdm\n",
                "\n",
                "print(\"‚úÖ Imports ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 2: Paths\n",
                "# ============================================================\n",
                "INCLUDE_DIR = Path('/kaggle/input/include')  # Source dataset\n",
                "CACHE_DIR = Path('/kaggle/input/isl-123-cache/isl_cache_123')  # Cache directory\n",
                "MAPPING_FILE = Path('/kaggle/input/isl-123-cache/label_mapping_123.json')  # Label mapping\n",
                "OUTPUT_FILE = Path('/kaggle/working/file_to_label.json')  # Output\n",
                "\n",
                "print(f\"üìÇ Paths:\")\n",
                "print(f\"   INCLUDE: {INCLUDE_DIR}\")\n",
                "print(f\"   Cache: {CACHE_DIR}\")\n",
                "print(f\"   Mapping: {MAPPING_FILE}\")\n",
                "print(f\"   Output: {OUTPUT_FILE}\")\n",
                "\n",
                "# Verify paths exist\n",
                "if not INCLUDE_DIR.exists():\n",
                "    raise FileNotFoundError(f\"INCLUDE dataset not found at {INCLUDE_DIR}\")\n",
                "if not CACHE_DIR.exists():\n",
                "    raise FileNotFoundError(f\"Cache not found at {CACHE_DIR}\")\n",
                "if not MAPPING_FILE.exists():\n",
                "    raise FileNotFoundError(f\"Mapping not found at {MAPPING_FILE}\")\n",
                "\n",
                "print(\"\\n‚úÖ All paths verified\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 3: Load Label Mapping\n",
                "# ============================================================\n",
                "with open(MAPPING_FILE) as f:\n",
                "    mapping = json.load(f)\n",
                "\n",
                "label_to_id = mapping['label_to_id']\n",
                "print(f\"‚úÖ Loaded {len(label_to_id)} classes from mapping\")\n",
                "print(f\"\\nFirst 10 classes:\")\n",
                "for i, cls in enumerate(list(label_to_id.keys())[:10]):\n",
                "    print(f\"   {i+1}. {cls}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 4: Scan INCLUDE Dataset & Match to Cache\n",
                "# ============================================================\n",
                "print(\"=\"*60)\n",
                "print(\"üîç SCANNING INCLUDE DATASET\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# First, get all cache files\n",
                "cache_files = {f.stem: f.name for f in CACHE_DIR.glob('*.npy')}\n",
                "print(f\"\\nüì¶ Found {len(cache_files)} cache files\")\n",
                "\n",
                "# Now scan INCLUDE dataset to find source videos\n",
                "file_to_label = {}\n",
                "video_to_class = {}  # Track source video -> class mapping\n",
                "\n",
                "print(f\"\\nüîç Scanning INCLUDE directory structure...\")\n",
                "\n",
                "for root, dirs, files in os.walk(INCLUDE_DIR):\n",
                "    for file in files:\n",
                "        if file.lower().endswith(('.mov', '.mp4')):\n",
                "            # Get relative path\n",
                "            relative = Path(root).relative_to(INCLUDE_DIR)\n",
                "            parts = relative.parts\n",
                "            \n",
                "            # Extract class from folder structure\n",
                "            # Expected format: INCLUDE/Sign Videos/123 Classes/<number>. <class>/videos/file.mov\n",
                "            if len(parts) >= 3:\n",
                "                class_folder = parts[2]  # e.g., \"87. hot\"\n",
                "                \n",
                "                # Extract class name\n",
                "                if '. ' in class_folder:\n",
                "                    class_name = class_folder.split('. ', 1)[1].strip().lower()\n",
                "                else:\n",
                "                    class_name = class_folder.strip().lower()\n",
                "                \n",
                "                # Store mapping\n",
                "                video_stem = Path(file).stem\n",
                "                video_to_class[video_stem] = class_name\n",
                "\n",
                "print(f\"‚úÖ Found {len(video_to_class)} source videos\")\n",
                "\n",
                "# Match cache files to source videos\n",
                "print(f\"\\nüîó Matching cache files to classes...\")\n",
                "matched = 0\n",
                "unmatched = []\n",
                "\n",
                "for cache_stem, cache_name in tqdm(cache_files.items(), desc=\"Matching\"):\n",
                "    # Try exact match first\n",
                "    if cache_stem in video_to_class:\n",
                "        file_to_label[cache_name] = video_to_class[cache_stem]\n",
                "        matched += 1\n",
                "    else:\n",
                "        # Try partial match (cache might have extra suffixes)\n",
                "        found = False\n",
                "        for video_stem, class_name in video_to_class.items():\n",
                "            if video_stem in cache_stem or cache_stem in video_stem:\n",
                "                file_to_label[cache_name] = class_name\n",
                "                matched += 1\n",
                "                found = True\n",
                "                break\n",
                "        \n",
                "        if not found:\n",
                "            unmatched.append(cache_stem)\n",
                "\n",
                "print(f\"\\nüìä Matching Results:\")\n",
                "print(f\"   Matched: {matched}/{len(cache_files)}\")\n",
                "print(f\"   Unmatched: {len(unmatched)}\")\n",
                "\n",
                "if unmatched:\n",
                "    print(f\"\\n‚ö†Ô∏è  Unmatched files (first 10):\")\n",
                "    for u in unmatched[:10]:\n",
                "        print(f\"   {u}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 5: Verify Class Distribution\n",
                "# ============================================================\n",
                "print(\"=\"*60)\n",
                "print(\"üìä VERIFYING CLASS DISTRIBUTION\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "class_counts = Counter(file_to_label.values())\n",
                "\n",
                "print(f\"\\nüìà Statistics:\")\n",
                "print(f\"   Total samples: {len(file_to_label)}\")\n",
                "print(f\"   Total classes: {len(class_counts)}/{len(label_to_id)}\")\n",
                "print(f\"   Min/class: {min(class_counts.values())}\")\n",
                "print(f\"   Max/class: {max(class_counts.values())}\")\n",
                "print(f\"   Avg/class: {len(file_to_label)/len(class_counts):.1f}\")\n",
                "\n",
                "# Check for missing classes\n",
                "mapped_classes = set(class_counts.keys())\n",
                "expected_classes = set(label_to_id.keys())\n",
                "missing = expected_classes - mapped_classes\n",
                "\n",
                "if missing:\n",
                "    print(f\"\\n‚ö†Ô∏è  Warning: {len(missing)} classes have NO samples\")\n",
                "    print(f\"   First 10: {list(missing)[:10]}\")\n",
                "else:\n",
                "    print(f\"\\n‚úÖ All {len(label_to_id)} classes have samples!\")\n",
                "\n",
                "# Show top classes\n",
                "print(f\"\\nüîù Top 10 classes by sample count:\")\n",
                "for cls, count in class_counts.most_common(10):\n",
                "    print(f\"   {cls:20s}: {count:3d} samples\")\n",
                "\n",
                "# Show bottom classes\n",
                "print(f\"\\nüîª Bottom 10 classes by sample count:\")\n",
                "for cls, count in sorted(class_counts.items(), key=lambda x: x[1])[:10]:\n",
                "    print(f\"   {cls:20s}: {count:3d} samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 6: Save file_to_label.json\n",
                "# ============================================================\n",
                "print(\"=\"*60)\n",
                "print(\"üíæ SAVING file_to_label.json\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "with open(OUTPUT_FILE, 'w') as f:\n",
                "    json.dump(file_to_label, f, indent=2, sort_keys=True)\n",
                "\n",
                "print(f\"\\n‚úÖ Saved to: {OUTPUT_FILE}\")\n",
                "print(f\"   File size: {OUTPUT_FILE.stat().st_size / 1024:.1f} KB\")\n",
                "print(f\"   Total entries: {len(file_to_label)}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ DONE!\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nüìã Next steps:\")\n",
                "print(f\"   1. Download file_to_label.json from /kaggle/working\")\n",
                "print(f\"   2. Add it to your isl-123-cache dataset (re-upload)\")\n",
                "print(f\"   3. OR: Just use this file in the same notebook\")\n",
                "print(f\"\\nüí° Tip: In training notebook, change Cell 3 to:\")\n",
                "print(f\"   file_to_label_path = Path('/kaggle/working/file_to_label.json')\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}